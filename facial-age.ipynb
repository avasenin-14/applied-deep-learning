{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "efc27446",
      "metadata": {
        "id": "efc27446"
      },
      "source": [
        "Import dataset from kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cf7cda7",
      "metadata": {
        "id": "6cf7cda7"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"frabbisw/facial-age\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "639ad29b",
      "metadata": {
        "id": "639ad29b"
      },
      "source": [
        "Check the structure of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e36c46b3",
      "metadata": {
        "id": "e36c46b3"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "path = Path(path)\n",
        "\n",
        "def hierarchy(root: Path):\n",
        "    return { child: hierarchy(child) for child in root.iterdir() } if root.is_dir() else None\n",
        "\n",
        "path_dict = hierarchy(path)\n",
        "path_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d513da6",
      "metadata": {
        "id": "7d513da6"
      },
      "outputs": [],
      "source": [
        "path_dict = dict(list(path_dict.items())[0:])\n",
        "\n",
        "path_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de1e9e3d",
      "metadata": {
        "id": "de1e9e3d"
      },
      "outputs": [],
      "source": [
        "data = {}\n",
        "\n",
        "for directory in path_dict:\n",
        "    for age in path_dict[directory]:\n",
        "        for image in path_dict[directory][age]:\n",
        "            if image.is_file():\n",
        "                data[image] = age.name\n",
        "\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e171802",
      "metadata": {
        "id": "0e171802"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data = {'file' : data.keys(), 'age' : data.values()})\n",
        "print(df.sample(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ee7e3c7",
      "metadata": {
        "id": "6ee7e3c7"
      },
      "source": [
        "After manually inspecting the dataset, it was decided to drop some of the examples as they were either corrupted files, different body parts than face or having the wrong age."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97bef9e4",
      "metadata": {
        "id": "97bef9e4"
      },
      "outputs": [],
      "source": [
        "print(len(df))\n",
        "files_to_drop = [3829, 4313, 7034, 7326, 9378, 1490,]\n",
        "for filename in files_to_drop:\n",
        "    filename_with_extension = f\"{filename}.png\"\n",
        "    for index, row in df.iterrows():\n",
        "        if filename_with_extension in str(row.file):\n",
        "            print(row.file)\n",
        "            df = df.drop(index)\n",
        "\n",
        "print(len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9644ff87",
      "metadata": {
        "id": "9644ff87"
      },
      "outputs": [],
      "source": [
        "df.to_csv('facial-age.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "145a7395",
      "metadata": {
        "id": "145a7395"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "train, validate, test = \\\n",
        "              np.split(df.sample(frac=1),\n",
        "                       [int(.75*len(df)), int(.9*len(df))])\n",
        "\n",
        "print(len(train), len(validate), len(test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02239e40",
      "metadata": {
        "id": "02239e40"
      },
      "source": [
        "We can categorize ages into bins to simplify classification task.\n",
        "To start with it we can simple create bins with approximately equal number of examples in each.\n",
        "The downside of it is that we won't have as precise age in case of wider bins (where number of examples were low for some ages). And the upside is that we will have approximarely equal number of examples in each bin, which in theory will allow us to predict a category with more accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1098c7b2",
      "metadata": {
        "id": "1098c7b2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.countplot(data=df['age'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbea41f1",
      "metadata": {
        "id": "bbea41f1"
      },
      "outputs": [],
      "source": [
        "df['age'] = df['age'].astype(int)\n",
        "df['age_bins'] = pd.qcut(x=df['age'], q=8, precision=0)\n",
        "print(df.sample(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35eb35bd",
      "metadata": {
        "id": "35eb35bd"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a99dd32e",
      "metadata": {
        "id": "a99dd32e"
      },
      "outputs": [],
      "source": [
        "sns.countplot(data=df['age_bins'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Giving up and starting using LLMs to have a chance to get things done before the deadline."
      ],
      "metadata": {
        "id": "VYe_Vx2gTAod"
      },
      "id": "VYe_Vx2gTAod"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define the CNN architecture\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)), # Assuming image size 64x64 with 3 channels\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(8, activation='softmax') # Assuming 8 age bins from previous step\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Jb2-OHQVSqGm"
      },
      "id": "Jb2-OHQVSqGm",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}